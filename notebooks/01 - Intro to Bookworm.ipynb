{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Bookworm\n",
    "For the sake of coherence with what I've outiled in the README, I'm going to start with Infinite Jest. \n",
    "\n",
    "Go and have a quick look at the stripped down bookworm code in [bookworm.py](./bookworm.py). The first thing we're going to do is load in all of those functions. I'll also do some explanation of how each function works along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bookworm\n",
    "from bookworm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next thing to do is load in the book and the characters. These operations are both pretty simple. The book is loaded in as one long string from a `.txt` file. Character lists are stored in a `.csv`, with all potential names for a character stored on each row. They're loaded in as tuples of names in a list of characters.  \n",
    "\n",
    "Then we split the book down into sections. Bookworm works by looking for _coocurrence_ of characters in these sections of the text as a proxy for their connectedness. It's a very simple trick which works stupidly well.  \n",
    "There are a few ways we can break down the book into sections:\n",
    "- `get_sentence_sequences()` uses [NLTK](http://www.nltk.org/)'s standard `.tokenize()` function to split the book into sentences.  \n",
    "- `get_word_sequences()` uses [NLTK](http://www.nltk.org/)'s `word_tokenize()` to split the book into words, of which it will then select ordered lists of length `n` (default 40).  \n",
    "- `get_character_sequences()` uses python builtins to split it into substrings of length `n` (default 200).  \n",
    "\n",
    "Fundamentally, they all return a list of strings which each cover a very small section of the novel. For simplicity's sake we're going to use the sentence-wise splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book = load_book('../data/raw/ij.txt')\n",
    "characters = load_characters('../data/raw/characters_ij.csv')\n",
    "\n",
    "sequences = get_sentence_sequences(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the fun bit. We've assembled our cast, and moved the text that they inhabit into a nice, machine-interpretable format.  \n",
    "What we want to generate now is the blank table below which describes the presence of a character in a sentence. At this point, Bookworm hasn't really 'read' any of the text so all of the interactions between characters and sentences (where each cell in the table represents an interaction) are set to 0:\n",
    "\n",
    "|            | character 1 | character 2 | character 3 |\n",
    "|------------|-------------|-------------|-------------|\n",
    "| sentence 1 | 0           | 0           | 0           |\n",
    "| sentence 2 | 0           | 0           | 0           |\n",
    "| sentence 3 | 0           | 0           | 0           |\n",
    "| sentence 4 | 0           | 0           | 0           |\n",
    "\n",
    "\n",
    "However, tuples of names aren't that nicely placed into tables as column headings, and entire sentences (especially those in Infinite Jest) are inappropriately long to be used as row indexes. To get around this aesthetic lumpiness, we can set up a hash table for each of the lists, allowing us to move backwards and forwards quickly and easily between the tuple/text themselves and their numeric fingerprints.  \n",
    "Note: we'll be using pandas to build the table above so that hashing is obviously already being done automatically under the hood - doing it explicitly is a purely aesthetic choice.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_to_sequence, sequence_to_hash = get_hashes(sequences)\n",
    "hash_to_character, character_to_hash = get_hashes(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got:\n",
    "\n",
    "|                  | hash(character 1) | hash(character 2) | hash(character 3) |\n",
    "|------------------|-------------------|-------------------|-------------------|\n",
    "| hash(sentence 1) | 0                 | 0                 | 0                 |\n",
    "| hash(sentence 2) | 0                 | 0                 | 0                 |\n",
    "| hash(sentence 3) | 0                 | 0                 | 0                 |\n",
    "| hash(sentence 4) | 0                 | 0                 | 0                 |\n",
    "\n",
    "| hash              | character   |\n",
    "|-------------------|-------------|\n",
    "| hash(character 1) | character 1 |\n",
    "| hash(character 2) | character 2 |\n",
    "| hash(character 3) | character 3 |\n",
    "\n",
    "| hash             | sentence   |\n",
    "|------------------|------------|\n",
    "| hash(sentence 1) | sentence 1 |\n",
    "| hash(sentence 2) | sentence 2 |\n",
    "| hash(sentence 3) | sentence 3 |\n",
    "| hash(sentence 4) | sentence 4 |\n",
    "\n",
    "We also have the hash tables in reverse too, just in case they become useful later on.\n",
    "\n",
    "The first bit of the `find_connections()` function sets up the blank table above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = find_connections(sequences, characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it iterates through the list of sentences it has been fed, checking for an instance of each character. If it finds a character in the sentence, it marks their presence with a 1.  \n",
    "So if **character 1** appears with **character 2** in sentence 1, and with **character 3** in sentence 2, we would see the following, with the rest of the cells remaining blank:\n",
    "\n",
    "|                  | hash(character 1) | hash(character 2) | hash(character 3) |\n",
    "|------------------|-------------------|-------------------|-------------------|\n",
    "| hash(sentence 1) | 1                 | 1                 | 0                 |\n",
    "| hash(sentence 2) | 1                 | 0                 | 1                 |\n",
    "| hash(sentence 3) | 0                 | 0                 | 0                 |\n",
    "| hash(sentence 4) | 0                 | 0                 | 0                 |\n",
    "\n",
    "The next stage is the enumeration of coocurence. We can compute this very quickly with the `numpy` dot product of the table with its own transpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cooccurence = calculate_cooccurence(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calculate_cooccurence()` does this computation and then wipes out any interaction of a character with themselves. For the table above, this would give us:\n",
    "\n",
    "|                   | hash(character 1) | hash(character 2) | hash(character 3) |\n",
    "|-------------------|-------------------|-------------------|-------------------|\n",
    "| hash(character 1) | 0                 | 1                 | 1                 |\n",
    "| hash(character 2) | 1                 | 0                 | 0                 |\n",
    "| hash(character 3) | 1                 | 0                 | 0                 |\n",
    "\n",
    "showing that **character 1** has interacted with **character 2** and **character 3**, but **character 2** and **character 3** haven't interacted. Note the symmetry across the diagonal...\n",
    "\n",
    "Of course, the example table here is miniscule in comparison to the dozens of characters who might turn up in a reasonably sized novel, and the thousands of opportunities they have to interact. The coocurence matrix in reality is likely to contain much larger numbers between characters who regularly appear in the same sentences. Unless we're working with a _really_ tiny, incestuous network, this coocurence matrix is also probably going to be pretty sparse. For that reason it'll often make sense to store it as a sparse matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cooccurence = cooccurence.to_sparse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you now have a decent understanding of what Bookworm does, and how.\n",
    "\n",
    "We can now show some results! Despite describing a set of tiny matrices above, we've really been computing all of Infinite Jest's massiveness while working through the notebook.\n",
    "\n",
    "We can print the strongest relationships for a chosen character using the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_five_closest(character):\n",
    "    print('-'*len(str(character))\n",
    "          + '\\n' + str(character) + '\\n'\n",
    "          + '-'*len(str(character)))\n",
    "    \n",
    "    top_five = (cooccurence[hash(character)]\n",
    "                .sort_values(ascending=False)\n",
    "                .index.values\n",
    "                [:5])\n",
    "    \n",
    "    for hashed_name in top_five:\n",
    "        print(hash_to_character[hashed_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this to 5 characters at random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "('corbett thorp ',)\n",
      "-------------------\n",
      "('hugh pemberton ', 'pemberton ')\n",
      "('jim troeltsch ', 'troeltsch ')\n",
      "('mario ',)\n",
      "('desjardins ',)\n",
      "('balbalis ',)\n",
      "\n",
      "---------\n",
      "('hal ',)\n",
      "---------\n",
      "('ortho \"the darkness\" stice ', 'stice ', 'ortho ', 'the darkness ')\n",
      "('mario ',)\n",
      "('pemulis ',)\n",
      "('himself ', 'mad stork ', 'jim icandenza ', 'james incandenza ')\n",
      "('the moms ', 'avril ', 'mondragon ')\n",
      "\n",
      "-----------------------------\n",
      "('henri f. hoyne ', 'henri ')\n",
      "-----------------------------\n",
      "('desjardins ',)\n",
      "('chandler foss ', 'foss ')\n",
      "('wraith ',)\n",
      "('bob death ',)\n",
      "('attache ', 'saudi ')\n",
      "\n",
      "------------------------\n",
      "('dean of admissions ',)\n",
      "------------------------\n",
      "('desjardins ',)\n",
      "('chandler foss ', 'foss ')\n",
      "('wraith ',)\n",
      "('bob death ',)\n",
      "('attache ', 'saudi ')\n",
      "\n",
      "--------------------------\n",
      "('audern tallat-kelpsa ',)\n",
      "--------------------------\n",
      "('desjardins ',)\n",
      "('chandler foss ', 'foss ')\n",
      "('wraith ',)\n",
      "('bob death ',)\n",
      "('attache ', 'saudi ')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "for i in range(5):\n",
    "    print_five_closest(characters[randint(0, len(characters))])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those all seem to make sense... Lets try with a few characters who we know about in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "('the moms ', 'avril ', 'mondragon ')\n",
      "-------------------------------------\n",
      "('hal ',)\n",
      "('orin ',)\n",
      "('mario ',)\n",
      "('himself ', 'mad stork ', 'jim icandenza ', 'james incandenza ')\n",
      "('joelle ', 'van dyne ', 'lucille ')\n"
     ]
    }
   ],
   "source": [
    "print_five_closest(('the moms ', 'avril ', 'mondragon '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "('joelle ', 'van dyne ', 'lucille ')\n",
      "------------------------------------\n",
      "('orin ',)\n",
      "('gately ', 'don ')\n",
      "('the moms ', 'avril ', 'mondragon ')\n",
      "('erdedy ',)\n",
      "('himself ', 'mad stork ', 'jim icandenza ', 'james incandenza ')\n"
     ]
    }
   ],
   "source": [
    "print_five_closest(('joelle ', 'van dyne ', 'lucille '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "('pemulis ',)\n",
      "-------------\n",
      "('hal ',)\n",
      "('trevor \"axhandle\" axford ', 'axford ', 'axhandle ')\n",
      "('jim troeltsch ', 'troeltsch ')\n",
      "('james struck ', 'struck ')\n",
      "('keith freer ', 'freer ', 'the viking ')\n"
     ]
    }
   ],
   "source": [
    "print_five_closest(('pemulis ',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "('bruce green ',)\n",
      "-----------------\n",
      "('randy ', 'lenz ')\n",
      "('gately ', 'don ')\n",
      "('himself ', 'mad stork ', 'jim icandenza ', 'james incandenza ')\n",
      "('kate gompert ', 'gompert ')\n",
      "('erdedy ',)\n"
     ]
    }
   ],
   "source": [
    "print_five_closest(('bruce green ',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep...  Go and look at the diagram in the README and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same code, different book\n",
    "Lets run the whole thing for an entirely different book and see whether we get similarly positive results. This time, Harry Potter and The Philosopher's Stone - chosen because you're more likely to have some contextual knowledge of who's who and what's what in that book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = load_book('../data/raw/hp.txt')\n",
    "characters = load_characters('../data/raw/characters_hp.csv')\n",
    "sequences = get_sentence_sequences(book)\n",
    "\n",
    "hash_to_sequence, sequence_to_hash = get_hashes(sequences)\n",
    "hash_to_character, character_to_hash = get_hashes(characters)\n",
    "\n",
    "df = find_connections(sequences, characters)\n",
    "cooccurence = calculate_cooccurence(df).to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vernon ', ' dursley '),\n",
       " ('petunia ', ' dursley '),\n",
       " ('dudley ', ' duddy '),\n",
       " ('lily ',),\n",
       " ('james ',)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "('harry ', ' potter ')\n",
      "----------------------\n",
      "('ron ', ' weasley ')\n",
      "('hermione ', ' granger ')\n",
      "('hagrid ', ' rubeus ')\n",
      "('snape ', ' severus ')\n",
      "('dudley ', ' duddy ')\n"
     ]
    }
   ],
   "source": [
    "print_five_closest(('harry ', ' potter '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "('voldemort ', ' lord ', ' you-know-who ')\n",
      "------------------------------------------\n",
      "('harry ', ' potter ')\n",
      "('snape ', ' severus ')\n",
      "('quirrell ',)\n",
      "('ron ', ' weasley ')\n",
      "('dumbledore ', ' albus ')\n"
     ]
    }
   ],
   "source": [
    "print_five_closest(('voldemort ', ' lord ', ' you-know-who '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "('crabbe ',)\n",
      "------------\n",
      "('goyle ',)\n",
      "('draco ', ' malfoy ')\n",
      "('harry ', ' potter ')\n",
      "('fred ',)\n",
      "('george ',)\n"
     ]
    }
   ],
   "source": [
    "print_five_closest(('crabbe ',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "('fred ',)\n",
      "----------\n",
      "('george ',)\n",
      "('ron ', ' weasley ')\n",
      "('harry ', ' potter ')\n",
      "('katie bell ',)\n",
      "('sorting ', ' hat ')\n"
     ]
    }
   ],
   "source": [
    "print_five_closest(('fred ',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully that's enough proof that this thing works well. Go and look at the [next notebook](./02%20-%20Visualising Networks.ipynb) which covers a bit more network analysis and some ways in which we can visualise the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
